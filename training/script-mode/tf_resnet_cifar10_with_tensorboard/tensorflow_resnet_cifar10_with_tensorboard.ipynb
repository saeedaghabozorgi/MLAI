{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet CIFAR-10 with tensorboard\n",
    "\n",
    "This notebook shows how to use TensorBoard, and how the training job writes checkpoints to a external bucket.\n",
    "The model used for this notebook is a ResNet model, trained with the CIFAR-10 dataset.\n",
    "See the following papers for more background:\n",
    "\n",
    "[Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf) by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, Dec 2015.\n",
    "\n",
    "[Identity Mappings in Deep Residual Networks](https://arxiv.org/pdf/1603.05027.pdf) by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, Jul 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the CIFAR-10 dataset\n",
    "Downloading the test and training data will take around 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar dataset already downloaded\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "utils.cifar10_download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the data to a S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = sagemaker_session.upload_data(path='/tmp/cifar10_data', key_prefix='data/DEMO-cifar10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sagemaker_session.upload_data** will upload the CIFAR-10 dataset from your machine to a bucket named **sagemaker-{region}-{*your aws account number*}**, if you don't have this bucket yet, sagemaker_session will create it for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete source code\n",
    "- [source_dir/resnet_model.py](source_dir/resnet_model.py): ResNet model\n",
    "- [source_dir/resnet_cifar_10.py](source_dir/resnet_cifar_10.py): main script used for training and hosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a training job using the sagemaker.TensorFlow estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"sagemaker\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-06 22:10:41 Starting - Starting the training job...\n",
      "2020-05-06 22:10:43 Starting - Launching requested ML instances......\n",
      "2020-05-06 22:11:49 Starting - Preparing the instances for training......\n",
      "2020-05-06 22:13:00 Downloading - Downloading input data...\n",
      "2020-05-06 22:13:38 Training - Training image download completed. Training in progress..\u001b[35m2020-05-06 22:13:36,861 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[35m2020-05-06 22:13:36,861 INFO - root - starting train task\u001b[0m\n",
      "\u001b[35m2020-05-06 22:13:36,875 INFO - container_support.training - Training starting\u001b[0m\n",
      "\u001b[35mDownloading s3://sagemaker-us-east-1-079329190341/tensorboard-example-2020-05-06-22-10-40-569/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[34m2020-05-06 22:13:39,421 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[34m2020-05-06 22:13:39,422 INFO - root - starting train task\u001b[0m\n",
      "\u001b[34m2020-05-06 22:13:39,434 INFO - container_support.training - Training starting\u001b[0m\n",
      "\u001b[34mDownloading s3://sagemaker-us-east-1-079329190341/tensorboard-example-2020-05-06-22-10-40-569/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[34m2020-05-06 22:13:44,885 INFO - tf_container - ----------------------TF_CONFIG--------------------------\u001b[0m\n",
      "\u001b[34m2020-05-06 22:13:44,885 INFO - tf_container - {\"environment\": \"cloud\", \"cluster\": {\"worker\": [\"algo-2:2222\"], \"ps\": [\"algo-1:2223\", \"algo-2:2223\"], \"master\": [\"algo-1:2222\"]}, \"task\": {\"index\": 0, \"type\": \"master\"}}\u001b[0m\n",
      "\u001b[34m2020-05-06 22:13:44,885 INFO - tf_container - ---------------------------------------------------------\u001b[0m\n",
      "\u001b[34m2020-05-06 22:13:44,885 INFO - tf_container - creating RunConfig:\u001b[0m\n",
      "\u001b[34m2020-05-06 22:13:44,885 INFO - tf_container - {'save_checkpoints_secs': 300}\u001b[0m\n",
      "\u001b[34m2020-05-06 22:13:44,885 INFO - tensorflow - TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {u'ps': [u'algo-1:2223', u'algo-2:2223'], u'worker': [u'algo-2:2222'], u'master': [u'algo-1:2222']}, u'task': {u'index': 0, u'type': u'master'}}\u001b[0m\n",
      "\u001b[34m2020-05-06 22:13:44,886 INFO - tf_container - creating an estimator from the user-provided model_fn\u001b[0m\n",
      "\u001b[34m2020-05-06 22:13:44,887 INFO - tensorflow - Using config: {'_save_checkpoints_secs': 300, '_keep_checkpoint_max': 5, '_task_type': u'master', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb81c1440d0>, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 2, '_tf_random_seed': None, '_device_fn': None, '_num_worker_replicas': 2, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_session_config': device_filters: \"/job:ps\"\u001b[0m\n",
      "\u001b[34mdevice_filters: \"/job:master\"\u001b[0m\n",
      "\u001b[34mallow_soft_placement: true\u001b[0m\n",
      "\u001b[34mgraph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m, '_global_id_in_cluster': 0, '_is_chief': True, '_protocol': None, '_save_checkpoints_steps': None, '_experimental_distribute': None, '_save_summary_steps': 100, '_model_dir': u's3://sagemaker-us-east-1-079329190341/tensorboard-example-2020-05-06-22-10-40-569/checkpoints', '_master': u'grpc://algo-1:2222'}\u001b[0m\n",
      "\u001b[34m2020-05-06 22:13:44,888 INFO - tensorflow - Not using Distribute Coordinator.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:13:44,889 INFO - tensorflow - Start Tensorflow server.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:13:45,253 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:13:48,063 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:13:48,064 INFO - tensorflow - Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:13:49,651 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[35m2020-05-06 22:13:55,058 INFO - tf_container - ----------------------TF_CONFIG--------------------------\u001b[0m\n",
      "\u001b[35m2020-05-06 22:13:55,059 INFO - tf_container - {\"environment\": \"cloud\", \"cluster\": {\"worker\": [\"algo-2:2222\"], \"ps\": [\"algo-1:2223\", \"algo-2:2223\"], \"master\": [\"algo-1:2222\"]}, \"task\": {\"index\": 0, \"type\": \"worker\"}}\u001b[0m\n",
      "\u001b[35m2020-05-06 22:13:55,059 INFO - tf_container - ---------------------------------------------------------\u001b[0m\n",
      "\u001b[35m2020-05-06 22:13:55,059 INFO - tf_container - creating RunConfig:\u001b[0m\n",
      "\u001b[35m2020-05-06 22:13:55,059 INFO - tf_container - {'save_checkpoints_secs': 300}\u001b[0m\n",
      "\u001b[35m2020-05-06 22:13:55,059 INFO - tensorflow - TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {u'ps': [u'algo-1:2223', u'algo-2:2223'], u'worker': [u'algo-2:2222'], u'master': [u'algo-1:2222']}, u'task': {u'index': 0, u'type': u'worker'}}\u001b[0m\n",
      "\u001b[35m2020-05-06 22:13:55,060 INFO - tf_container - creating an estimator from the user-provided model_fn\u001b[0m\n",
      "\u001b[35m2020-05-06 22:13:55,060 INFO - tensorflow - Using config: {'_save_checkpoints_secs': 300, '_keep_checkpoint_max': 5, '_task_type': u'worker', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7edc4e2150>, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 2, '_tf_random_seed': None, '_device_fn': None, '_num_worker_replicas': 2, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_session_config': device_filters: \"/job:ps\"\u001b[0m\n",
      "\u001b[35mdevice_filters: \"/job:worker/task:0\"\u001b[0m\n",
      "\u001b[35mallow_soft_placement: true\u001b[0m\n",
      "\u001b[35mgraph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35m, '_global_id_in_cluster': 1, '_is_chief': False, '_protocol': None, '_save_checkpoints_steps': None, '_experimental_distribute': None, '_save_summary_steps': 100, '_model_dir': u's3://sagemaker-us-east-1-079329190341/tensorboard-example-2020-05-06-22-10-40-569/checkpoints', '_master': u'grpc://algo-2:2222'}\u001b[0m\n",
      "\u001b[35m2020-05-06 22:13:55,062 INFO - tensorflow - Not using Distribute Coordinator.\u001b[0m\n",
      "\u001b[35m2020-05-06 22:13:55,063 INFO - tensorflow - Start Tensorflow server.\u001b[0m\n",
      "\u001b[35m2020-05-06 22:13:55,098 INFO - tensorflow - Waiting 5 secs before starting training.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:13:56,579 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:13:56,637 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:14:00,171 INFO - tensorflow - Saving checkpoints for 0 into s3://sagemaker-us-east-1-079329190341/tensorboard-example-2020-05-06-22-10-40-569/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[35m2020-05-06 22:14:00,319 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[35m2020-05-06 22:14:03,126 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[35m2020-05-06 22:14:03,127 INFO - tensorflow - Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[35m2020-05-06 22:14:04,369 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[35m2020-05-06 22:14:04,836 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[35m2020-05-06 22:14:04,931 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:14:14,739 INFO - tensorflow - loss = 2.6374457, step = 0\u001b[0m\n",
      "\u001b[35m2020-05-06 22:14:15,475 INFO - tensorflow - loss = 2.6900945, step = 0\u001b[0m\n",
      "\u001b[35m2020-05-06 22:15:03,181 INFO - tensorflow - global_step/sec: 2.22479\u001b[0m\n",
      "\u001b[34m2020-05-06 22:15:25,445 INFO - tensorflow - loss = 2.0400684, step = 161 (70.707 sec)\u001b[0m\n",
      "\u001b[35m2020-05-06 22:15:45,293 INFO - tensorflow - global_step/sec: 2.44585\u001b[0m\n",
      "\u001b[35m2020-05-06 22:16:09,673 INFO - tensorflow - loss = 1.8770884, step = 265 (114.198 sec)\u001b[0m\n",
      "\u001b[35m2020-05-06 22:16:28,550 INFO - tensorflow - global_step/sec: 2.35797\u001b[0m\n",
      "\u001b[34m2020-05-06 22:16:33,075 INFO - tensorflow - loss = 1.9257334, step = 322 (67.630 sec)\u001b[0m\n",
      "\u001b[35m2020-05-06 22:17:10,004 INFO - tensorflow - global_step/sec: 2.46057\u001b[0m\n",
      "\u001b[34m2020-05-06 22:17:40,297 INFO - tensorflow - loss = 1.5071931, step = 486 (67.222 sec)\u001b[0m\n",
      "\u001b[35m2020-05-06 22:17:52,458 INFO - tensorflow - global_step/sec: 2.42619\u001b[0m\n",
      "\u001b[35m2020-05-06 22:17:54,496 INFO - tensorflow - loss = 1.485679, step = 520 (104.823 sec)\u001b[0m\n",
      "\u001b[35m2020-05-06 22:18:34,540 INFO - tensorflow - global_step/sec: 2.44761\u001b[0m\n",
      "\u001b[34m2020-05-06 22:18:46,939 INFO - tensorflow - loss = 1.4647175, step = 650 (66.642 sec)\u001b[0m\n",
      "\u001b[34m2020-05-06 22:19:03,026 INFO - tensorflow - Saving checkpoints for 691 into s3://sagemaker-us-east-1-079329190341/tensorboard-example-2020-05-06-22-10-40-569/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:19:05,785 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:19:06,776 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:19:06,794 INFO - tensorflow - Starting evaluation at 2020-05-06-22:19:06\u001b[0m\n",
      "\u001b[34m2020-05-06 22:19:07,319 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:19:07,387 INFO - tensorflow - Restoring parameters from s3://sagemaker-us-east-1-079329190341/tensorboard-example-2020-05-06-22-10-40-569/checkpoints/model.ckpt-691\u001b[0m\n",
      "\u001b[34m2020-05-06 22:19:08,019 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:19:08,037 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:19:10,843 INFO - tensorflow - Evaluation [10/100]\u001b[0m\n",
      "\u001b[34m2020-05-06 22:19:12,944 INFO - tensorflow - Evaluation [20/100]\u001b[0m\n",
      "\u001b[34m2020-05-06 22:19:14,900 INFO - tensorflow - Evaluation [30/100]\u001b[0m\n",
      "\u001b[34m2020-05-06 22:19:16,812 INFO - tensorflow - Evaluation [40/100]\u001b[0m\n",
      "\u001b[34m2020-05-06 22:19:18,786 INFO - tensorflow - Evaluation [50/100]\u001b[0m\n",
      "\u001b[34m2020-05-06 22:19:20,723 INFO - tensorflow - Evaluation [60/100]\u001b[0m\n",
      "\u001b[34m2020-05-06 22:19:22,717 INFO - tensorflow - Evaluation [70/100]\u001b[0m\n",
      "\u001b[34m2020-05-06 22:19:24,390 INFO - tensorflow - Finished evaluation at 2020-05-06-22:19:24\u001b[0m\n",
      "\u001b[34m2020-05-06 22:19:24,391 INFO - tensorflow - Saving dict for global step 691: accuracy = 0.3145, global_step = 691, loss = 3.1920269\u001b[0m\n",
      "\u001b[34m2020-05-06 22:19:25,303 INFO - tensorflow - Saving 'checkpoint_path' summary for global step 691: s3://sagemaker-us-east-1-079329190341/tensorboard-example-2020-05-06-22-10-40-569/checkpoints/model.ckpt-691\u001b[0m\n",
      "\u001b[34m2020-05-06 22:19:25,811 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:19:26,604 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:19:26,604 INFO - tensorflow - Signatures INCLUDED in export for Eval: None\u001b[0m\n",
      "\u001b[34m2020-05-06 22:19:26,604 INFO - tensorflow - Signatures INCLUDED in export for Classify: None\u001b[0m\n",
      "\u001b[34m2020-05-06 22:19:26,604 INFO - tensorflow - Signatures INCLUDED in export for Regress: None\u001b[0m\n",
      "\u001b[34m2020-05-06 22:19:26,604 INFO - tensorflow - Signatures INCLUDED in export for Predict: ['serving_default']\u001b[0m\n",
      "\u001b[34m2020-05-06 22:19:26,604 INFO - tensorflow - Signatures INCLUDED in export for Train: None\u001b[0m\n",
      "\u001b[34m2020-05-06 22:19:26,819 INFO - tensorflow - Restoring parameters from s3://sagemaker-us-east-1-079329190341/tensorboard-example-2020-05-06-22-10-40-569/checkpoints/model.ckpt-691\u001b[0m\n",
      "\u001b[34m2020-05-06 22:19:27,290 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py:1046: calling add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mPass your op to the equivalent parameter main_op instead.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:19:27,290 INFO - tensorflow - Assets added to graph.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:19:27,290 INFO - tensorflow - No assets to write.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:19:28,547 INFO - tensorflow - SavedModel written to: s3://sagemaker-us-east-1-079329190341/tensorboard-example-2020-05-06-22-10-40-569/checkpoints/export/Servo/1588803565/saved_model.pb\u001b[0m\n",
      "\u001b[35m2020-05-06 22:19:31,342 INFO - tensorflow - global_step/sec: 1.7957\u001b[0m\n",
      "\u001b[35m2020-05-06 22:19:38,845 INFO - tensorflow - loss = 1.3426192, step = 738 (104.349 sec)\u001b[0m\n",
      "\u001b[35m2020-05-06 22:20:13,234 INFO - tensorflow - global_step/sec: 2.43483\u001b[0m\n",
      "\u001b[34m2020-05-06 22:20:19,708 INFO - tensorflow - loss = 1.3168521, step = 839 (92.769 sec)\u001b[0m\n",
      "\u001b[35m2020-05-06 22:20:54,924 INFO - tensorflow - global_step/sec: 2.4466\u001b[0m\n",
      "\u001b[35m2020-05-06 22:21:22,473 INFO - tensorflow - loss = 1.1604507, step = 992 (103.628 sec)\u001b[0m\n",
      "\u001b[35m2020-05-06 22:21:26,090 INFO - tensorflow - Loss for final step: 1.1828116.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:24,974 INFO - tensorflow - Saving checkpoints for 1001 into s3://sagemaker-us-east-1-079329190341/tensorboard-example-2020-05-06-22-10-40-569/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:27,214 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:28,090 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:28,108 INFO - tensorflow - Starting evaluation at 2020-05-06-22:21:28\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:28,602 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:29,097 INFO - tensorflow - Restoring parameters from s3://sagemaker-us-east-1-079329190341/tensorboard-example-2020-05-06-22-10-40-569/checkpoints/model.ckpt-1001\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:29,652 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:29,670 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:32,397 INFO - tensorflow - Evaluation [10/100]\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:34,271 INFO - tensorflow - Evaluation [20/100]\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:36,210 INFO - tensorflow - Evaluation [30/100]\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:38,089 INFO - tensorflow - Evaluation [40/100]\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:39,941 INFO - tensorflow - Evaluation [50/100]\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:41,883 INFO - tensorflow - Evaluation [60/100]\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:43,888 INFO - tensorflow - Evaluation [70/100]\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:45,465 INFO - tensorflow - Finished evaluation at 2020-05-06-22:21:45\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:45,466 INFO - tensorflow - Saving dict for global step 1001: accuracy = 0.4069, global_step = 1001, loss = 2.7512746\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:45,696 INFO - tensorflow - Saving 'checkpoint_path' summary for global step 1001: s3://sagemaker-us-east-1-079329190341/tensorboard-example-2020-05-06-22-10-40-569/checkpoints/model.ckpt-1001\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:46,017 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:46,797 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:46,797 INFO - tensorflow - Signatures INCLUDED in export for Eval: None\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:46,797 INFO - tensorflow - Signatures INCLUDED in export for Classify: None\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:46,797 INFO - tensorflow - Signatures INCLUDED in export for Regress: None\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:46,797 INFO - tensorflow - Signatures INCLUDED in export for Predict: ['serving_default']\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:46,797 INFO - tensorflow - Signatures INCLUDED in export for Train: None\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:47,047 INFO - tensorflow - Restoring parameters from s3://sagemaker-us-east-1-079329190341/tensorboard-example-2020-05-06-22-10-40-569/checkpoints/model.ckpt-1001\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:47,617 INFO - tensorflow - Assets added to graph.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:47,618 INFO - tensorflow - No assets to write.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:48,621 INFO - tensorflow - SavedModel written to: s3://sagemaker-us-east-1-079329190341/tensorboard-example-2020-05-06-22-10-40-569/checkpoints/export/Servo/1588803705/saved_model.pb\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:48,805 INFO - tensorflow - Loss for final step: 1.1650357.\u001b[0m\n",
      "\u001b[34m2020-05-06 22:21:49,107 INFO - tf_container - Downloaded saved model at /opt/ml/model/export/Servo/1588803705\u001b[0m\n",
      "\u001b[35m2020-05-06 22:23:04,276 INFO - tf_container - master algo-1 is down, stopping parameter server\u001b[0m\n",
      "\n",
      "2020-05-06 22:23:47 Uploading - Uploading generated training model\n",
      "2020-05-06 22:23:54 Completed - Training job completed\n",
      "Training seconds: 1308\n",
      "Billable seconds: 1308\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "\n",
    "source_dir = os.path.join(os.getcwd(), 'source_dir')\n",
    "estimator = TensorFlow(entry_point='resnet_cifar_10.py',\n",
    "                       source_dir=source_dir,\n",
    "                       role=role,\n",
    "                       framework_version='1.12.0',\n",
    "                       hyperparameters={'throttle_secs': 30},\n",
    "                       training_steps=1000, evaluation_steps=100,\n",
    "                       train_instance_count=2, train_instance_type='ml.c4.xlarge', \n",
    "                       base_job_name='tensorboard-example')\n",
    "\n",
    "estimator.fit(inputs, run_tensorboard_locally=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **```fit```** method will create a training job named **```tensorboard-example-{unique identifier}```** in two **ml.c4.xlarge** instances. These instances will write checkpoints to the s3 bucket **```sagemaker-{your aws account number}```**.\n",
    "\n",
    "If you don't have this bucket yet, **```sagemaker_session```** will create it for you. These checkpoints can be used for restoring the training job, and to analyze training job metrics using **TensorBoard**. \n",
    "\n",
    "The parameter **```run_tensorboard_locally=True```** will run **TensorBoard** in the machine that this notebook is running. Everytime a new checkpoint is created by the training job in the S3 bucket, **```fit```** will download the checkpoint to the temp folder that **TensorBoard** is pointing to.\n",
    "\n",
    "When the **```fit```** method starts the training, it will log the port that **TensorBoard** is using to display the metrics. The default port is **6006**, but another port can be choosen depending on its availability. The port number will increase until finds an available port. After that the port number will printed in stdout.\n",
    "\n",
    "It takes a few minutes to provision containers and start the training job.**TensorBoard** will start to display metrics shortly after that.\n",
    "\n",
    "You can access **TensorBoard** locally at [http://localhost:6006](http://localhost:6006) or using your SageMaker notebook instance [proxy/6006/](/proxy/6006/)(TensorBoard will not work if forget to put the slash, '/', in end of the url). If TensorBoard started on a different port, adjust these URLs to match.This example uses the optional hyperparameter **```throttle_secs```** to generate training evaluations more often, allowing to visualize **TensorBoard** scalar data faster. You can find the available optional hyperparameters [here](https://github.com/aws/sagemaker-python-sdk#optional-hyperparameters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the trained model to prepare for predictions\n",
    "\n",
    "The deploy() method creates an endpoint which serves prediction requests in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a prediction with fake data to verify the endpoint is up\n",
    "\n",
    "Prediction is not the focus of this notebook, so to verify the endpoint's functionality, we'll simply generate random data in the correct shape and make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_spec': {'name': u'generic_model',\n",
       "  'signature_name': u'serving_default',\n",
       "  'version': {'value': 1588803705L}},\n",
       " 'outputs': {u'classes': {'dtype': 9,\n",
       "   'int64_val': [6L],\n",
       "   'tensor_shape': {'dim': [{'size': 1L}]}},\n",
       "  u'probabilities': {'dtype': 1,\n",
       "   'float_val': [0.0044905380345880985,\n",
       "    0.00014152491348795593,\n",
       "    0.015392323955893517,\n",
       "    0.0027393086347728968,\n",
       "    0.0008531171479262412,\n",
       "    1.7411322914995253e-05,\n",
       "    0.7100078463554382,\n",
       "    3.045869743800722e-05,\n",
       "    0.2637484669685364,\n",
       "    0.0025790617801249027],\n",
       "   'tensor_shape': {'dim': [{'size': 1L}, {'size': 10L}]}}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "random_image_data = np.random.rand(32, 32, 3)\n",
    "predictor.predict(random_image_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning up\n",
    "To avoid incurring charges to your AWS account for the resources used in this tutorial you need to delete the **SageMaker Endpoint:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p27",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
